{"cells":[{"cell_type":"code","source":["from delta.tables import DeltaTable\n","from pyspark.sql.functions import col\n","from pyspark.sql.types import StructType, StructField, StringType, DateType, BooleanType, DecimalType, DoubleType"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dbc0078c-8fbe-4973-ac45-091d8222ba70"},{"cell_type":"code","source":["schema = StructType([\n","    StructField('TPAccountName', StringType(), False),\n","    StructField('EnrollmentCustomerName', StringType(), True),\n","    StructField('SubscriptionGUID', StringType(), False),\n","    StructField('SubscriptionName', StringType(), False),\n","    StructField('FiscalMonth', DateType(), False),\n","    StructField('$ Organic ACR', DoubleType(), False),\n","    StructField('$ Average Daily Organic ACR', DoubleType(), False),\n","    StructField('ServiceLevel1', StringType(), False),\n","    StructField('ServiceLevel2', StringType(), False),\n","    StructField('ServiceLevel4', StringType(), False),\n","    StructField('FiscalYear', StringType(), False),\n","])"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d6fccdfa-f09e-4d78-b842-b1fe77c5ada8"},{"cell_type":"code","source":["df = spark.read.format(\"parquet\").load(\"Files/*.parquet\", schema=schema) \\\n","    .withColumn(\"$ Organic ACR\", col(\"$ Organic ACR\").cast(DecimalType(19, 4))) \\\n","    .withColumn(\"$ Average Daily Organic ACR\", col(\"$ Average Daily Organic ACR\").cast(DecimalType(19, 4)))"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5acbc64c-c1d2-4cd7-928c-4f9ad31ff756"},{"cell_type":"code","source":["# Rename columns to Delta Lake compatible names\n","df_renamed = df \\\n","    .withColumnRenamed('TPAccountName', 'tp_account_name') \\\n","    .withColumnRenamed('EnrollmentCustomerName', 'enrollment_customer_name') \\\n","    .withColumnRenamed('SubscriptionGUID', 'subscription_guid') \\\n","    .withColumnRenamed('SubscriptionName', 'subscription_name') \\\n","    .withColumnRenamed('FiscalMonth', 'fiscal_month') \\\n","    .withColumnRenamed('$ Organic ACR', 'organic_acr_usd') \\\n","    .withColumnRenamed('$ Average Daily Organic ACR', 'avg_daily_organic_acr_usd') \\\n","    .withColumnRenamed('ServiceLevel1', 'service_level_1') \\\n","    .withColumnRenamed('ServiceLevel2', 'service_level_2') \\\n","    .withColumnRenamed('ServiceLevel4', 'service_level_4') \\\n","    .withColumnRenamed('FiscalYear', 'fiscal_year')\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0fc903bf-5367-42b2-a41e-b73b77974785"},{"cell_type":"code","source":["# Define your target table path\n","target_table_path = \"Tables/acr\"\n","\n","# Check if the Delta table already exists\n","if DeltaTable.isDeltaTable(spark, target_table_path):\n","    # Table exists - perform merge\n","    delta_table = DeltaTable.forPath(spark, target_table_path)\n","    \n","    # Define the merge condition (adjust based on your business keys)\n","    merge_condition = \"\"\"\n","        target.tp_account_name = source.tp_account_name\n","        AND target.enrollment_customer_name = source.enrollment_customer_name\n","        AND target.service_level_1 = source.service_level_1\n","        AND target.service_level_2 = source.service_level_2\n","        AND target.service_level_4 = source.service_level_4\n","        AND target.subscription_guid = source.subscription_guid \n","        AND target.fiscal_month = source.fiscal_month\n","    \"\"\"\n","    \n","    delta_table.alias(\"target\").merge(\n","        df_renamed.alias(\"source\"),\n","        merge_condition\n","    ).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n","    \n","else:\n","    # Table doesn't exist - create it\n","    df_renamed.write.mode(\"overwrite\").format(\"delta\").save(target_table_path)\n","    print(\"Created new Delta table\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a42942ff-fdb2-44fe-ac1d-a85f2275349c"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"synapse_pyspark","language":null,"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"f3552d5c-3df8-4889-902e-8d2ea0bfdf1f","default_lakehouse_name":"LH_acr","default_lakehouse_workspace_id":"b2a91082-1f0e-404e-bf25-6d717b635637","known_lakehouses":[{"id":"fc3319ae-ef7e-43f9-a2ae-f515d749a082"},{"id":"f3552d5c-3df8-4889-902e-8d2ea0bfdf1f"}]}}},"nbformat":4,"nbformat_minor":5}
